{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JulianCarax01/Fondamenti-web-app/blob/main/DijkstraSerialCPPMerge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dijkstra_serialMerge.cu\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cstdlib>\n",
        "#include <climits>\n",
        "#include <cuda.h>\n",
        "#include <curand_kernel.h>\n",
        "\n",
        "#define GRIDSIZE 1024\n",
        "#define BLOCKSIZE 1024\n",
        "\n",
        "// Kernel CUDA per aggiornare le distanze\n",
        "__global__ void cudaNodeRelax(int *graph, int *distances, char *visited, int n, int currentNode) {\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x; // Stabiliamo l'indice generale del thread tramite le formule viste a lezione\n",
        "\n",
        "    // Verifichiamo che l'indice sia inferiore al numero totale dei nodi e che il nodo non sia già stato visitato,\n",
        "    // inoltre facciamo un check per verificare che la distanza tra due nodi non sia zero\n",
        "    if (idx < n && !visited[idx] && graph[currentNode * n + idx] > 0) {\n",
        "        int newDist = distances[currentNode] + graph[currentNode * n + idx];\n",
        "        atomicMin(&distances[idx], newDist); // Aggiorniamo la distanza usando atomicMin per evitare condizioni di gara\n",
        "    }\n",
        "    __syncthreads();\n",
        "}\n",
        "\n",
        "__global__ void findClosestNodeCUDA(int* d_graph, int d_distances[], char* d_visited, int n){\n",
        "  //calcolo di thread id per unrolling\n",
        "  //int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  for (int i = 0; i < n; ++i) {\n",
        "\n",
        "        // Troviamo il nodo non visitato con distanza minima\n",
        "        int minDist = INT_MAX;\n",
        "        int currentNode = -1;\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            // Controlliamo che il nodo non sia stato visitato e che la distanza sia inferiore a quella nota\n",
        "            if (!d_visited[j] && d_distances[j] < minDist) {\n",
        "                minDist = d_distances[j];\n",
        "                currentNode = j;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if (currentNode == -1) break; // Se non ci sono più nodi raggiungibili\n",
        "        d_visited[currentNode] = 1;\n",
        "/*\n",
        "        // Aggiorna le distanze in parallelo\n",
        "        cudaMemcpy(d_distances, distances.data(), n * sizeof(int), cudaMemcpyHostToDevice);\n",
        "        cudaMemcpy(d_visited, visited.data(), n * sizeof(char), cudaMemcpyHostToDevice);*/\n",
        "\n",
        "        cudaNodeRelax<<<64, 64>>>(d_graph, d_distances, d_visited, n, currentNode);\n",
        "        __syncthreads();\n",
        "/*\n",
        "        cudaMemcpy(distances.data(), d_distances, n * sizeof(int), cudaMemcpyDeviceToHost);*/\n",
        "    }\n",
        "}\n",
        "\n",
        "// Funzione host per eseguire Dijkstra in CUDA\n",
        "void dijkstraCUDA(int *graph, int n, int start) {\n",
        "    // Allocazione memoria su GPU\n",
        "    int *d_graph; //puntatore memorua gpu\n",
        "    int *d_distances;\n",
        "    char *d_visited; // Usiamo un tipo char per verificare che il nodo sia già stato verificato o no (non riesco a farlo con il bool)\n",
        "\n",
        "    // Utilizziamo la malloc per andare ad allocare sulla memoria\n",
        "    cudaMalloc((void **)&d_graph, n * n * sizeof(int));\n",
        "    cudaMalloc((void **)&d_distances, n * sizeof(int));\n",
        "    cudaMalloc((void **)&d_visited, n * sizeof(char));\n",
        "\n",
        "    // Inizializza distanze e visited\n",
        "    std::vector<int> distances(n, INT_MAX);\n",
        "    std::vector<char> visited(n, 0);\n",
        "    distances[start] = 0;\n",
        "\n",
        "    // Copia grafico su GPU\n",
        "    cudaMemcpy(d_graph, graph, n * n * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_distances, distances.data(), n * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_visited, visited.data(), n * sizeof(char), cudaMemcpyHostToDevice); // Cambiato da bool a char\n",
        "\n",
        "    // Esegui Dijkstra iterativamente\n",
        "\n",
        "    findClosestNodeCUDA <<<1024, 1024>>>(d_graph, d_distances, d_visited, n);\n",
        "\n",
        "    // Libera memoria GPU\n",
        "    cudaFree(d_graph);\n",
        "    cudaFree(d_distances);\n",
        "    cudaFree(d_visited);\n",
        "\n",
        "      /* // Stampa la matrice con \"X\" sulla diagonale\n",
        "    std::cout << \"Matrice del grafo:\\n\";\n",
        "    for (int i = 0; i < n; ++i) {\n",
        "        for (int j = 0; j < n; ++j) {\n",
        "            if (i == j) {\n",
        "                std::cout << \"X \"; // Stampa \"X\" sulla diagonale\n",
        "            } else {\n",
        "                std::cout << graph[i * n + j] << \" \";\n",
        "            }\n",
        "        }\n",
        "        std::cout << \"\\n\";\n",
        "    }\n",
        "\n",
        "    // Stampa solo le distanze alla fine\n",
        "    std::cout << \"Distanze dal nodo iniziale:\\n\";\n",
        "    for (int i = 0; i < n; ++i) {\n",
        "        if (distances[i] == INT_MAX) {\n",
        "            std::cout << \"Nodo \" << i << \": NON ESISTE COLLEGAMENTO TRA I NODI\\n\";\n",
        "        } else {\n",
        "            std::cout << \"Nodo \" << i << \": \" << distances[i] << \"\\n\";\n",
        "        }\n",
        "    } */\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "__global__ void generateGraphKernel(int *graph, int n, int minWeight, int maxWeight, unsigned int seed) {\n",
        "    int row_start = blockIdx.y * 4; // Prima riga gestita dal blocco (4 righe consecutive)\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x; // Colonna gestita dal thread nel blocco\n",
        "\n",
        "    // Dichiarazione degli stati casuali per 4 righe\n",
        "    curandState state[4];\n",
        "\n",
        "    // Inizializzazione dei generatori casuali per le 4 righe\n",
        "    if (row_start < n) curand_init(seed + row_start, 0, 0, &state[0]);\n",
        "    if (row_start + 1 < n) curand_init(seed + row_start + 1, 0, 0, &state[1]);\n",
        "    if (row_start + 2 < n) curand_init(seed + row_start + 2, 0, 0, &state[2]);\n",
        "    if (row_start + 3 < n) curand_init(seed + row_start + 3, 0, 0, &state[3]);\n",
        "\n",
        "    // Gestione esplicita di ogni riga\n",
        "    if (row_start < n && col < n) {\n",
        "        // Riga 0\n",
        "        if (row_start < col) {\n",
        "            int zero_generator = curand(&state[0]) % 100 + 1;\n",
        "            int weight = (zero_generator <= 40)\n",
        "                         ? curand(&state[0]) % (maxWeight - minWeight + 1) + minWeight\n",
        "                         : 0;\n",
        "            graph[row_start * n + col] = weight;\n",
        "            graph[col * n + row_start] = weight;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (row_start + 1 < n && col < n) {\n",
        "        // Riga 1\n",
        "        if (row_start + 1 < col) {\n",
        "            int zero_generator = curand(&state[1]) % 100 + 1;\n",
        "            int weight = (zero_generator <= 40)\n",
        "                         ? curand(&state[1]) % (maxWeight - minWeight + 1) + minWeight\n",
        "                         : 0;\n",
        "            graph[(row_start + 1) * n + col] = weight;\n",
        "            graph[col * n + (row_start + 1)] = weight;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (row_start + 2 < n && col < n) {\n",
        "        // Riga 2\n",
        "        if (row_start + 2 < col) {\n",
        "            int zero_generator = curand(&state[2]) % 100 + 1;\n",
        "            int weight = (zero_generator <= 40)\n",
        "                         ? curand(&state[2]) % (maxWeight - minWeight + 1) + minWeight\n",
        "                         : 0;\n",
        "            graph[(row_start + 2) * n + col] = weight;\n",
        "            graph[col * n + (row_start + 2)] = weight;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (row_start + 3 < n && col < n) {\n",
        "        // Riga 3\n",
        "        if (row_start + 3 < col) {\n",
        "            int zero_generator = curand(&state[3]) % 100 + 1;\n",
        "            int weight = (zero_generator <= 40)\n",
        "                         ? curand(&state[3]) % (maxWeight - minWeight + 1) + minWeight\n",
        "                         : 0;\n",
        "            graph[(row_start + 3) * n + col] = weight;\n",
        "            graph[col * n + (row_start + 3)] = weight;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Assicura che la diagonale sia sempre 0\n",
        "    if (col == row_start && row_start < n) {\n",
        "        graph[row_start * n + row_start] = 0;\n",
        "    }\n",
        "    if (col == row_start + 1 && row_start + 1 < n) {\n",
        "        graph[(row_start + 1) * n + (row_start + 1)] = 0;\n",
        "    }\n",
        "    if (col == row_start + 2 && row_start + 2 < n) {\n",
        "        graph[(row_start + 2) * n + (row_start + 2)] = 0;\n",
        "    }\n",
        "    if (col == row_start + 3 && row_start + 3 < n) {\n",
        "        graph[(row_start + 3) * n + (row_start + 3)] = 0;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "void generateGraphCUDA(int *graph, int n, int minWeight, int maxWeight) {\n",
        "    int *d_graph;\n",
        "    size_t size = n * n * sizeof(int);\n",
        "\n",
        "    // Allocazione della memoria sulla GPU\n",
        "    if (cudaMalloc(&d_graph, size) != cudaSuccess) {\n",
        "        std::cerr << \"Errore nell'allocazione della memoria sulla GPU.\" << std::endl;\n",
        "        return;\n",
        "    }\n",
        "    if (cudaMemset(d_graph, 0, size) != cudaSuccess) {\n",
        "        std::cerr << \"Errore durante l'inizializzazione della memoria sulla GPU.\" << std::endl;\n",
        "        cudaFree(d_graph);\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    const int blockSize = 256; // Numero di thread per blocco lungo l'asse x //Marco dobbiamo testare qui daje ROMA\n",
        "dim3 threadsPerBlock(blockSize); // Blocchi 1D (solo sull'asse x)\n",
        "dim3 blocksPerGrid((n + blockSize - 1) / blockSize, n); // Griglia 2D\n",
        "\n",
        "\n",
        "    // Lancio del kernel\n",
        "generateGraphKernel<<<blocksPerGrid, threadsPerBlock>>>(d_graph, n, minWeight, maxWeight, time(NULL));\n",
        "    if (cudaDeviceSynchronize() != cudaSuccess) {\n",
        "        std::cerr << \"Errore durante l'esecuzione del kernel.\" << std::endl;\n",
        "        cudaFree(d_graph);\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    // Copia i dati dalla GPU alla CPU\n",
        "    if (cudaMemcpy(graph, d_graph, size, cudaMemcpyDeviceToHost) != cudaSuccess) {\n",
        "        std::cerr << \"Errore nella copia dei dati dalla GPU alla CPU.\" << std::endl;\n",
        "        cudaFree(d_graph);\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    // Libera memoria sulla GPU\n",
        "    cudaFree(d_graph);\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "    int n = 1024; // Numero di nodi\n",
        "    int start = 0; // Nodo iniziale\n",
        "    int minWeight = 1;\n",
        "    int maxWeight = 5000;\n",
        "\n",
        "    // Genera il grafo casuale\n",
        "    std::vector<int> graph(n * n);\n",
        "    generateGraphCUDA(graph.data(), n, minWeight, maxWeight);\n",
        "\n",
        "    dijkstraCUDA(graph.data(), n, start);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehGdrkqPxtF8",
        "outputId": "adcd10c7-460f-4737-9cc4-1fd4e32cbecc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dijkstra_serialMerge.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ncu --mode launch-and-attach -o profile --target-processes all --nvtx --call-stack --section ComputeWorkloadAnalysis --section MemoryWorkloadAnalysis -f ./dijkstra_serialMerge.o\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Bx_4VKs4zwdy",
        "outputId": "739736c8-a42b-41c1-ad0d-0a501a757acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==PROF== Connected to process 32883 (/content/dijkstra_serialMerge.o)\n",
            "==PROF== Profiling \"generateGraphKernel\" - 0: 0%....50%....100% - 8 passes\n",
            "==PROF== Profiling \"findClosestNodeCUDA\" - 1: 0%....50%....100% - 8 passes\n",
            "==PROF== Disconnected from process 32883\n",
            "==PROF== Report: /content/profile.ncu-rep\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2ZvKsxVmzJMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -rdc=true dijkstra_serialMerge.cu -lcudadevrt -o dijkstra_serialMerge.o"
      ],
      "metadata": {
        "id": "Wzi_aeYoc8Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ncu --target-processes=all ./dijkstra_serialMerge.o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhzCX5ZXenHW",
        "outputId": "5de5b5d3-de83-4b6d-988d-79dd82a03a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==PROF== Connected to process 33243 (/content/dijkstra_serialMerge.o)\n",
            "==PROF== Profiling \"generateGraphKernel\" - 0: 0%....50%....100% - 8 passes\n",
            "==PROF== Profiling \"findClosestNodeCUDA\" - 1: 0%....50%....100% - 8 passes\n",
            "==PROF== Disconnected from process 33243\n",
            "[33243] dijkstra_serialMerge.o@127.0.0.1\n",
            "  generateGraphKernel(int *, int, int, int, unsigned int) (64, 64, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ------------- -------------\n",
            "    Metric Name               Metric Unit  Metric Value\n",
            "    ----------------------- ------------- -------------\n",
            "    DRAM Frequency          cycle/nsecond          4.94\n",
            "    SM Frequency            cycle/usecond        578.23\n",
            "    Elapsed Cycles                  cycle    31,092,761\n",
            "    Memory Throughput                   %         47.04\n",
            "    DRAM Throughput                     %          4.21\n",
            "    Duration                      msecond         53.77\n",
            "    L1/TEX Cache Throughput             %         94.08\n",
            "    L2 Cache Throughput                 %         40.69\n",
            "    SM Active Cycles                cycle 29,565,243.80\n",
            "    Compute (SM) Throughput             %         27.19\n",
            "    ----------------------- ------------- -------------\n",
            "\n",
            "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
            "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
            "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  4,096\n",
            "    Registers Per Thread             register/thread              37\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    Threads                                   thread       1,048,576\n",
            "    Waves Per SM                                               25.60\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            6\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        94.19\n",
            "    Achieved Active Warps Per SM           warp        30.14\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    INF   This kernel's theoretical occupancy is not impacted by any block limit.                                       \n",
            "\n",
            "  findClosestNodeCUDA(int *, int *, char *, int) (1024, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ------------- -------------\n",
            "    Metric Name               Metric Unit  Metric Value\n",
            "    ----------------------- ------------- -------------\n",
            "    DRAM Frequency          cycle/nsecond          4.87\n",
            "    SM Frequency            cycle/usecond        570.66\n",
            "    Elapsed Cycles                  cycle    67,492,361\n",
            "    Memory Throughput                   %         56.56\n",
            "    DRAM Throughput                     %         14.52\n",
            "    Duration                      msecond        118.27\n",
            "    L1/TEX Cache Throughput             %         62.29\n",
            "    L2 Cache Throughput                 %         11.19\n",
            "    SM Active Cycles                cycle 71,184,495.12\n",
            "    Compute (SM) Throughput             %         64.16\n",
            "    ----------------------- ------------- -------------\n",
            "\n",
            "    INF   Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. \n",
            "          Check both the Compute Workload Analysis and Memory Workload Analysis sections.                               \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                 1,024\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              32\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    Threads                                   thread       1,048,576\n",
            "    Waves Per SM                                               25.60\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            2\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            1\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        91.24\n",
            "    Achieved Active Warps Per SM           warp        29.20\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    INF   This kernel's theoretical occupancy is not impacted by any block limit.                                       \n",
            "\n"
          ]
        }
      ]
    }
  ]
}